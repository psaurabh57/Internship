{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9c899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c0354",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae63452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver1= webdriver.Chrome('chromedriver.exe')\n",
    "driver1.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bad525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fbf58f115fc874d9a28facdc1ed5470d\", element=\"4db890f3-e694-4b9e-b69b-7f5aa422230c\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the element to search the job title using xpath\n",
    "search_job = driver1.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div[1]/input')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5443d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27f82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the job location using xpath and sending the keyword to it\n",
    "search_location = driver1.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div[1]/div[5]/div/div/div/input')\n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4d39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver1.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177797b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "for i in driver1.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]'):\n",
    "    job_location.append(i.text)\n",
    "\n",
    "for i in driver1.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "    experience_required.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f82e825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr. Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infometry</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business &amp; Data Analyst- Assistant Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>State Street</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manager / Senior Manager - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst(Power BI/Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore Rural, Bhopal, Indore, New Delhi, Pu...</td>\n",
       "      <td>Netlink Software</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Analyst - Data Strategy</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco</td>\n",
       "      <td>9-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA Analyst- Immediate Joining</td>\n",
       "      <td>Bangalore/Bengaluru(Cox Town)</td>\n",
       "      <td>ADVISETREE CONSULTING PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest India Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job Title  \\\n",
       "0                   Sr. Business Data Analyst   \n",
       "1  Business & Data Analyst- Assistant Manager   \n",
       "2     Manager / Senior Manager - Data Analyst   \n",
       "3        Senior Data Analyst(Power BI/Python)   \n",
       "4                            Sr. Data Analyst   \n",
       "5            Business Analyst - Data Strategy   \n",
       "6             DATA Analyst- Immediate Joining   \n",
       "7                         Senior Data Analyst   \n",
       "8                         Senior Data Analyst   \n",
       "9                            Sr. Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Bangalore Rural, Bhopal, Indore, New Delhi, Pu...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru(Cox Town)   \n",
       "7               Bangalore/Bengaluru(Old Madras Road)   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                          Bangalore/Bengaluru, Pune   \n",
       "\n",
       "                              Company Name Experience Required  \n",
       "0                                Infometry             4-6 Yrs  \n",
       "1                             State Street             1-3 Yrs  \n",
       "2                Huquo Consulting Pvt. Ltd             2-7 Yrs  \n",
       "3                         Societe Generale             3-7 Yrs  \n",
       "4                         Netlink Software             3-6 Yrs  \n",
       "5                                    Capco            9-11 Yrs  \n",
       "6    ADVISETREE CONSULTING PRIVATE LIMITED             3-5 Yrs  \n",
       "7                                 KrazyBee             3-6 Yrs  \n",
       "8          Qualitest India Private Limited             5-8 Yrs  \n",
       "9  Global Indian School Education Services            6-11 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df1=pd.DataFrame({'Job Title':job_title[:10],'Job Location':job_location[:10],'Company Name':company_name[:10],'Experience Required':experience_required[:10]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071273c",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b5b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver2= webdriver.Chrome('chromedriver.exe')\n",
    "driver2.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d0c0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"72c4127ac63149763b73a3b9938dcac0\", element=\"23b6d241-a540-4ffc-86be-6a8278e92b07\")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the element to search the job title using xpath\n",
    "search_job = driver2.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div[1]/input')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fffcd635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6533b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the job location using xpath and sending the keyword to it\n",
    "search_location = driver2.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div[1]/div[5]/div/div/div/input')\n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d94b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver2.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6b97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "for i in driver2.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver2.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]'):\n",
    "    job_location.append(i.text)\n",
    "\n",
    "for i in driver2.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "    company_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d263438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Lead_Tata Consultancy Services(...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "2  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                                  Lead ML Scientist   \n",
       "5                      Tcs Hiring For Data Scientist   \n",
       "6   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8  Data Scientist Lead_Tata Consultancy Services(...   \n",
       "9                   Assistant Manager - Data Science   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "2  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4                        Bangalore/Bengaluru, Mumbai   \n",
       "5   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "9                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "\n",
       "                                  Company Name  \n",
       "0                                    Accenture  \n",
       "1              TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                                        Wipro  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                            Fractal Analytics  \n",
       "5              TATA CONSULTANCY SERVICES (TCS)  \n",
       "6                                          PwC  \n",
       "7                                        Wipro  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)  \n",
       "9                                   CitiusTech  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df2=pd.DataFrame({'Job Title':job_title[:10],'Job Location':job_location[:10],'Company Name':company_name[:10]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674fec8",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb61cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver3= webdriver.Chrome('chromedriver.exe')\n",
    "driver3.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f836a4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fd24c6463c882444b6f2150bc84fb569\", element=\"7f16d21a-0b2c-439a-a9dd-39b5bb2f3d3c\")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the element to search the job title using xpath\n",
    "search_job = driver3.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div[1]/input')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9730324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae9145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver3.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3281e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter as per question\n",
    "job_location= driver3.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i')\n",
    "job_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bec87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary= driver3.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964ac3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "for i in driver3.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]'):\n",
    "    job_location.append(i.text)\n",
    "\n",
    "for i in driver3.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "    experience_required.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a0ca4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chat-bot Developer / Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "1                   Data Scientist - Noida/Bangalore   \n",
       "2                    DigitalBCG GAMMA Data Scientist   \n",
       "3                                Lead Data Scientist   \n",
       "4              Data Scientist - Predictive Analytics   \n",
       "5                                     Data Scientist   \n",
       "6                Chat-bot Developer / Data Scientist   \n",
       "7                Data Scientist / Chat-bot Developer   \n",
       "8                                     Data Scientist   \n",
       "9                  Data Scientist - Engine Algorithm   \n",
       "\n",
       "                                        Job Location             Company Name  \\\n",
       "0  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...                    Wipro   \n",
       "1                         Noida, Bangalore/Bengaluru                      EXL   \n",
       "2                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "3                             Noida(Sector-59 Noida)  R Systems International   \n",
       "4  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             Confidential   \n",
       "5                                   Gurgaon/Gurugram                    Optum   \n",
       "6             Mumbai, New Delhi, Bangalore/Bengaluru             Big Seo Buzz   \n",
       "7  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "8                                   Gurgaon/Gurugram           Feedback Infra   \n",
       "9  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...             Primo Hiring   \n",
       "\n",
       "  Experience Required  \n",
       "0            5-10 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             2-5 Yrs  \n",
       "3            7-10 Yrs  \n",
       "4             1-6 Yrs  \n",
       "5             2-7 Yrs  \n",
       "6             2-7 Yrs  \n",
       "7             3-7 Yrs  \n",
       "8             2-4 Yrs  \n",
       "9             1-3 Yrs  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df3=pd.DataFrame({'Job Title':job_title[:10],'Job Location':job_location[:10],'Company Name':company_name[:10],'Experience Required':experience_required[:10]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be2632",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: Brand, Product Description, Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6c0bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver4= webdriver.Chrome('chromedriver.exe')\n",
    "driver4.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd5ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting cancel button by element using xpath to cancel login popup\n",
    "search_btn=driver4.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f59f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the product using xpath\n",
    "search_job = driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8609068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1164c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required urls in a particular list\n",
    "import time\n",
    "urls=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for i in range(start,end):\n",
    "    time.sleep(2)\n",
    "    nb=driver4.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver4.get(nb[1].get_attribute('href'))\n",
    "        url=driver4.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))\n",
    "        \n",
    "    except:\n",
    "        driver4.get(nb[0].get_attribute('href'))\n",
    "        url=driver4.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d0bc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "ptitle=[]\n",
    "des=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver4.get(i)\n",
    "    for title_tag in driver4.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        ptitle.append(title_tag.text)\n",
    "    \n",
    "    for des_tag in driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):\n",
    "        des.append(des_tag.text)\n",
    "    \n",
    "    for price_tag in driver4.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(price_tag.text)\n",
    "    \n",
    "    for dis_tag in driver4.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "        discount.append(dis_tag.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fae5198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹359</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹849</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>₹849</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹281</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product Title                                        Description Price  \\\n",
       "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹949   \n",
       "1   VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹949   \n",
       "2        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹359   \n",
       "3        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799   \n",
       "4        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "..            ...                                                ...   ...   \n",
       "95  VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹849   \n",
       "96       Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹639   \n",
       "97  VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...  ₹849   \n",
       "98  VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...  ₹749   \n",
       "99   Silver Kartz           UV Protection Clubmaster Sunglasses (53)  ₹281   \n",
       "\n",
       "   Discount  \n",
       "0   52% off  \n",
       "1   52% off  \n",
       "2   55% off  \n",
       "3   20% off  \n",
       "4   20% off  \n",
       "..      ...  \n",
       "95  57% off  \n",
       "96  20% off  \n",
       "97  57% off  \n",
       "98  62% off  \n",
       "99  81% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df4=pd.DataFrame({'Product Title':ptitle[:100],'Description':des[:100],'Price':price[:100],'Discount':discount[:100]})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5608e3e",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "\n",
    "You will reach to the below shown webpage .\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "133d440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver5= webdriver.Chrome('chromedriver.exe')\n",
    "driver5.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f4e275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting cancel button by element using xpath to cancel login popup\n",
    "search_btn=driver5.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94a95797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the product using xpath\n",
    "search_job = driver5.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baafc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver5.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e45f351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the first product by element using xpath\n",
    "select_1=driver5.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a')\n",
    "url=select_1.get_attribute('href')\n",
    "driver5.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a68acb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting button by element using xpath to view all the reviews\n",
    "search_btn=driver5.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/a')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f0aefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required urls in a particular list\n",
    "urls=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "for i in range(start,end):\n",
    "    time.sleep(2)\n",
    "    nb=driver5.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver5.get(nb[1].get_attribute('href'))\n",
    "        url=driver5.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))\n",
    "        \n",
    "    except:\n",
    "        driver5.get(nb[0].get_attribute('href'))\n",
    "        url=driver5.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f5003f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver5.get(i)\n",
    "    for rt in driver5.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]'):\n",
    "        try:\n",
    "            rating.append(rt.text)\n",
    "        except:\n",
    "            rating.append(\"NA\")\n",
    "    \n",
    "    for rs in driver5.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "        try:\n",
    "            review_summary.append(rs.text)\n",
    "        except:\n",
    "            review_summary.append(\"NA\")\n",
    "    \n",
    "    for fr in driver5.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div'):\n",
    "        try:\n",
    "            full_review.append(fr.text)\n",
    "        except:\n",
    "            full_review.append(\"NA\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01682a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Don’t expect much from front camera… especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Flipkart honoured on time delivery, I have use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Absolutely powerful gadget. Loved it’s look! S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5         Simply awesome   \n",
       "1       5       Perfect product!   \n",
       "2       5    Best in the market!   \n",
       "3       5     Highly recommended   \n",
       "4       5      Worth every penny   \n",
       "..    ...                    ...   \n",
       "95      5              Excellent   \n",
       "96      5    Best in the market!   \n",
       "97      5                 Super!   \n",
       "98      5  Mind-blowing purchase   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Just go for it.\\nThis phone is really amazing....  \n",
       "96  Don’t expect much from front camera… especiall...  \n",
       "97  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "98  Flipkart honoured on time delivery, I have use...  \n",
       "99  Absolutely powerful gadget. Loved it’s look! S...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df5=pd.DataFrame({'Rating':rating,'Review Summary':review_summary,'Full Review':full_review})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb30952",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc6ec256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver6= webdriver.Chrome('chromedriver.exe')\n",
    "driver6.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f85c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting cancel button by element using xpath to cancel login popup\n",
    "search_btn=driver6.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b78a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the product using xpath\n",
    "search_job = driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b5ca745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61164d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required urls in a particular list\n",
    "\n",
    "urls=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for i in range(start,end):\n",
    "    time.sleep(2)\n",
    "    nb=driver6.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver6.get(nb[1].get_attribute('href'))\n",
    "        url=driver6.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))\n",
    "        \n",
    "    except:\n",
    "        driver6.get(nb[0].get_attribute('href'))\n",
    "        url=driver6.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        urls.append(url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36d64ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "ptitle=[]\n",
    "des=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver6.get(i)\n",
    "    for title_tag in driver6.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        try:\n",
    "            ptitle.append(title_tag.text)\n",
    "        except:\n",
    "            ptitle.append(\"NA\")\n",
    "    \n",
    "    for des_tag in driver6.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[1]'):\n",
    "        try:\n",
    "            des.append(des_tag.text)\n",
    "        except:\n",
    "            des.append(\"NA\")\n",
    "    \n",
    "    for price_tag in driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        try:\n",
    "            price.append(price_tag.text)\n",
    "        except:\n",
    "            price.append(\"NA\")\n",
    "    \n",
    "    for dis_tag in driver6.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "        try:\n",
    "            discount.append(dis_tag.text)\n",
    "        except:\n",
    "            discount.append(\"NA\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b51a0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Stylish Walking Partywear Sneakers Casual Shoe...</td>\n",
       "      <td>₹559</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DXMODA</td>\n",
       "      <td>Stylish And Trendy Casual Sneakers For Men Sne...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹374</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rebound JOY Sneakers For Men</td>\n",
       "      <td>₹3,134</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MOZAFIA</td>\n",
       "      <td>Canvas Casuals Shoes Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹509</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹259</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹959</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TUNER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Title                                        Description   Price  \\\n",
       "0         Shozie  Stylish Walking Partywear Sneakers Casual Shoe...    ₹559   \n",
       "1         DXMODA  Stylish And Trendy Casual Sneakers For Men Sne...    ₹699   \n",
       "2       Magnolia                                   Sneakers For Men    ₹374   \n",
       "3       Magnolia                                   Sneakers For Men    ₹399   \n",
       "4           PUMA                       Rebound JOY Sneakers For Men  ₹3,134   \n",
       "..           ...                                                ...     ...   \n",
       "95       MOZAFIA              Canvas Casuals Shoes Sneakers For Men    ₹799   \n",
       "96     ROCKFIELD                                   Sneakers For Men    ₹509   \n",
       "97        Kzaara                                   Sneakers For Men    ₹259   \n",
       "98      Roadster                                   Sneakers For Men    ₹959   \n",
       "99         TUNER                                   Sneakers For Men    ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   44% off  \n",
       "1   30% off  \n",
       "2   62% off  \n",
       "3   60% off  \n",
       "4   43% off  \n",
       "..      ...  \n",
       "95  60% off  \n",
       "96  66% off  \n",
       "97  74% off  \n",
       "98  69% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df6=pd.DataFrame({'Product Title':ptitle[:100],'Description':des[:100],'Price':price[:100],'Discount':discount[:100]})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fe914",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5918049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver7= webdriver.Chrome('chromedriver.exe')\n",
    "driver7.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d8220bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting checkbox using xpath\n",
    "check_color = driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "check_color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc6a5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_price = driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "check_price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fee3762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required urls in a particular list\n",
    "urls=[]\n",
    "\n",
    "start=0\n",
    "end=4\n",
    "for i in range(start,end):\n",
    "    time.sleep(2)\n",
    "    nb=driver7.find_elements_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    url=driver7.find_element_by_xpath(\"//li[@class='pagination-active']/a\")\n",
    "    urls.append(url.get_attribute('href'))\n",
    "    driver7.get(nb[0].get_attribute('href'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "031f0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting required details in a particular list\n",
    "ptitle=[]\n",
    "des=[]\n",
    "price=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver7.get(i)\n",
    "    for title_tag in driver7.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "        try:\n",
    "            ptitle.append(title_tag.text)\n",
    "        except:\n",
    "            ptitle.append(\"NA\")\n",
    "    \n",
    "    for des_tag in driver7.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "        try:\n",
    "            des.append(des_tag.text)\n",
    "        except:\n",
    "            des.append(\"NA\")\n",
    "    \n",
    "    for price_tag in driver7.find_elements_by_xpath('//div[@class=\"product-price\"]/span[1]'):\n",
    "        try:\n",
    "            price.append(price_tag.find_element_by_class_name(\"product-discountedPrice\").text.split()[1])\n",
    "        except:\n",
    "            price.append(price_tag.text.split()[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "972ccff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>10795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Electrify Nitro Running Shoes</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Solid Oznova Sneakers</td>\n",
       "      <td>11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Formal Leather Slip-Ons</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Sandals with Buckles</td>\n",
       "      <td>8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women ARCH FIT Slip-On Sneaker</td>\n",
       "      <td>7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Leather Block Sandals</td>\n",
       "      <td>7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>6990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Product Title                         Description  Price\n",
       "0               Nike      Men ZOOM WINFLO8 Running Shoes   7880\n",
       "1               Nike          Men Colourblocked Sneakers  10795\n",
       "2               Puma       Electrify Nitro Running Shoes   9999\n",
       "3   ADIDAS Originals           Men Solid Oznova Sneakers  11999\n",
       "4       Hush Puppies   Men Solid Leather Formal Slip-Ons   7649\n",
       "..               ...                                 ...    ...\n",
       "95          DAVINCHI         Men Formal Leather Slip-Ons   8990\n",
       "96           Saint G  Leather Block Sandals with Buckles   8505\n",
       "97          Skechers      Women ARCH FIT Slip-On Sneaker   7499\n",
       "98              Geox               Leather Block Sandals   7693\n",
       "99         J.FONTINI     Men Solid Leather Formal Derbys   6990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df7=pd.DataFrame({'Product Title':ptitle[:100],'Description':des[:100],'Price':price[:100]})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf674bb",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3af7398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver8= webdriver.Chrome('chromedriver.exe')\n",
    "driver8.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8417768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the element to search the product using xpath\n",
    "search_job = driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "#sending the keyword to the previously selected element \n",
    "search_job.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3300abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e36c0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "search_btn=driver8.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7bb7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the urls in a list\n",
    "urls=[]\n",
    "num=0\n",
    "for i in driver8.find_elements_by_xpath('//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]'):\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    num=num+1\n",
    "    if num==10:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9aefbe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the data in a list\n",
    "ptitle=[]\n",
    "price=[]\n",
    "rating=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver8.get(i)\n",
    "    try:\n",
    "        title_tag = driver8.find_element_by_xpath('//*[@id=\"productTitle\"]')\n",
    "        ptitle.append(title_tag.text)\n",
    "    except:\n",
    "        ptitle.append(\"NA\")\n",
    "    try:\n",
    "        price_tag = driver8.find_element_by_xpath('//*[@id=\"corePriceDisplay_desktop_feature_div\"]/div[1]/span[2]/span[2]/span[2]')\n",
    "        price.append(price_tag.text)\n",
    "    except:\n",
    "        price.append(\"NA\")\n",
    "    try:\n",
    "        rating_tag = driver8.find_element_by_xpath('//span[@class=\"a-size-base a-nowrap\"]/span')\n",
    "        rating.append(rating_tag.text.split()[0])\n",
    "    except:\n",
    "        rating.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "04240109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0cade610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...</td>\n",
       "      <td>94,999</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,490</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>55,990</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,490</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>87,990</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 11th Gen Intel Core i7 15.6 inches...</td>\n",
       "      <td>86,450</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>80,990</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Product Title   Price Rating\n",
       "0  LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...  94,999    4.5\n",
       "1  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  79,490    3.6\n",
       "2  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...      NA    3.9\n",
       "3  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  55,990    3.5\n",
       "4  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  79,490    3.6\n",
       "5  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  87,990    4.1\n",
       "6  HP Pavilion 11th Gen Intel Core i7 15.6 inches...  86,450    4.3\n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  80,990    4.2\n",
       "8  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...  84,990    4.6\n",
       "9  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  89,990    4.2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df8=pd.DataFrame({'Product Title':ptitle,'Price':price,'Rating':rating})\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943324c",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a90b1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver9= webdriver.Chrome('chromedriver.exe')\n",
    "driver9.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "69f59dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "select_job=driver9.find_element_by_xpath('//*[@id=\"headerWrapper\"]/nav[2]/div/ul/li[5]/a')\n",
    "select_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5fa3c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending key as data scientist \n",
    "search_job=driver9.find_element_by_xpath('//*[@id=\"jobs-typeahead\"]/span/input')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f6055e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "get_job=driver9.find_element_by_xpath('//*[@id=\"jobs\"]/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "get_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "80e19394",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_location=driver9.find_element_by_xpath('//*[@id=\"filters-row\"]/div/div/div[2]/div[1]/p')\n",
    "select_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0900e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location=driver9.find_element_by_xpath('//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ca4a44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_location=driver9.find_element_by_xpath('//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "get_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a721fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "period=[]\n",
    "rating=[]\n",
    "\n",
    "for i in driver9.find_elements_by_xpath('//p[@class=\"company body-medium\"]'):\n",
    "    company.append(i.text)\n",
    "\n",
    "for i in driver9.find_elements_by_xpath('//div[@class=\"other-info\"]/span[1]'):\n",
    "    period.append(i.text.split()[0])\n",
    "    \n",
    "for i in driver9.find_elements_by_xpath('//div[@class=\"info\"]/div/div/a[1]/span'):\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "815cbee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>11d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>21d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>19d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>19d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>21d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>20d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Name  \\\n",
       "0                         CBRE South Asia Pvt Ltd   \n",
       "1                   GENPACT India Private Limited   \n",
       "2                                         Genpact   \n",
       "3        Ericsson India Global Services Pvt. Ltd.   \n",
       "4                   GENPACT India Private Limited   \n",
       "5  Optum Global Solutions (India) Private Limited   \n",
       "6  Optum Global Solutions (India) Private Limited   \n",
       "7        Ericsson India Global Services Pvt. Ltd.   \n",
       "8                      SOPRA STERIA INDIA LIMITED   \n",
       "9                EXL Services.com ( I ) Pvt. Ltd.   \n",
       "\n",
       "  No. of days ago when job was posted Rating  \n",
       "0                                 11d    4.3  \n",
       "1                                  5d    4.0  \n",
       "2                                  6d    4.0  \n",
       "3                                 21d    4.3  \n",
       "4                                 14d    4.0  \n",
       "5                                 19d    4.1  \n",
       "6                                 19d    4.1  \n",
       "7                                1mon    4.3  \n",
       "8                                 21d    4.2  \n",
       "9                                 20d    3.9  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df9=pd.DataFrame({'Company Name':company,'No. of days ago when job was posted':period,'Rating':rating})\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331db47e",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "968930ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the webpage using webdriver\n",
    "driver10= webdriver.Chrome('chromedriver.exe')\n",
    "driver10.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a41bbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "select_sal=driver10.find_element_by_xpath('//*[@id=\"headerWrapper\"]/nav[2]/div/ul/li[3]/a')\n",
    "select_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e8733bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the button by element using xpath\n",
    "select_sal=driver10.find_element_by_xpath('//*[@id=\"subTab2\"]/ul/li[1]/div/div[2]/a')\n",
    "select_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "27b34465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending key as data scientist \n",
    "search_sal=driver10.find_element_by_xpath('//*[@id=\"jobProfileSearchbox\"]')\n",
    "search_sal.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4070b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sal=driver10.find_element_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "get_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5eaa1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "exp=[]\n",
    "nsal=[]\n",
    "minsal=[]\n",
    "avgsal=[]\n",
    "maxsal=[]\n",
    "\n",
    "main_tag = driver10.find_element_by_xpath('//div[@class=\"results-body\"]')\n",
    "\n",
    "for i in main_tag.find_elements_by_xpath('//div[@class=\"company-info\"]/a'):\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "for i in main_tag.find_elements_by_xpath('//div[@class=\"sbold-list-header\"]'):\n",
    "    exp.append(i.text.split()[0])\n",
    "for i in main_tag.find_elements_by_xpath('//div[@class=\"company-info\"]/div[1]/span'):\n",
    "    nsal.append(i.text.split()[2])\n",
    "for i in main_tag.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[1]'):\n",
    "    minsal.append(i.text)\n",
    "for i in main_tag.find_elements_by_xpath('//p[@class=\"averageCtc\"]'):\n",
    "    avgsal.append(i.text)\n",
    "for i in main_tag.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[2]'):\n",
    "    maxsal.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8e1c852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Salaries</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>22</td>\n",
       "      <td>3-4</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>53</td>\n",
       "      <td>2-4</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>48</td>\n",
       "      <td>2-4</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>33</td>\n",
       "      <td>1-2</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>109</td>\n",
       "      <td>2-4</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>65</td>\n",
       "      <td>2-4</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>91</td>\n",
       "      <td>2-4</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ford Motor</td>\n",
       "      <td>21</td>\n",
       "      <td>3-4</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name No. of Salaries Experience  Minimum Salary  \\\n",
       "0                     Walmart              22         3-4        ₹ 25.0L   \n",
       "1                    Ab Inbev              53         2-4        ₹ 15.0L   \n",
       "2                       Optum              48         2-4        ₹ 11.0L   \n",
       "3                          ZS              33         1-2        ₹ 11.0L   \n",
       "4           Fractal Analytics             109         2-4         ₹ 9.0L   \n",
       "5             Tiger Analytics              65         2-4         ₹ 9.0L   \n",
       "6  Legato Health Technologies              11           4        ₹ 11.0L   \n",
       "7                    Tredence              12           3         ₹ 8.8L   \n",
       "8                UnitedHealth              91         2-4         ₹ 8.0L   \n",
       "9                  Ford Motor              21         3-4        ₹ 10.0L   \n",
       "\n",
       "  Average Salary Maximum Salary  \n",
       "0        ₹ 31.7L        ₹ 45.0L  \n",
       "1        ₹ 19.7L        ₹ 25.5L  \n",
       "2        ₹ 16.5L        ₹ 22.6L  \n",
       "3        ₹ 15.7L        ₹ 22.0L  \n",
       "4        ₹ 15.2L        ₹ 23.0L  \n",
       "5        ₹ 14.7L        ₹ 20.0L  \n",
       "6        ₹ 14.5L        ₹ 20.0L  \n",
       "7        ₹ 14.1L        ₹ 17.5L  \n",
       "8        ₹ 13.6L        ₹ 20.5L  \n",
       "9        ₹ 13.5L        ₹ 18.0L  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing data in it\n",
    "df10=pd.DataFrame({'Company Name':company,'No. of Salaries':nsal,'Experience ':exp,'Minimum Salary':minsal,'Average Salary':avgsal,'Maximum Salary':maxsal})\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b30f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
